#!/bin/bash

# URL/endpoint discovery module

TARGET=$1
OUTPUT_DIR=$2
SUBDOMAINS_FILE="${RESULTS_DIR}/subdomains/vapt_${TARGET}_subdomains_all.txt"

# Ensure output directory exists
mkdir -p "${OUTPUT_DIR}"

# Function to crawl a domain for URLs
crawl_domain() {
    local domain=$1
    local output_file="${OUTPUT_DIR}/vapt_${TARGET}_urls_${domain}.txt"
    
    echo "Crawling ${domain} with Katana..." | tee -a "${LOG_FILE}"
    ${KATANA_PATH} -u "https://${domain}" ${KATANA_OPTIONS} -o "${output_file}" 2>/dev/null
    
    echo "Crawling ${domain} with HackCrawler..." | tee -a "${LOG_FILE}"
    ${HACKCRAWLER_PATH} -u "https://${domain}" ${HACKCRAWLER_OPTIONS} -o "${output_file}.hackcrawler" 2>/dev/null
    
    # Combine results
    cat "${output_file}" "${output_file}.hackcrawler" | sort -u > "${output_file}.combined"
    mv "${output_file}.combined" "${output_file}"
    rm "${output_file}.hackcrawler"
}

# Crawl the main domain
crawl_domain "${TARGET}"

# Crawl subdomains
while IFS= read -r subdomain; do
    crawl_domain "${subdomain}"
done < "${SUBDOMAINS_FILE}"

# Combine all URLs and remove duplicates
cat "${OUTPUT_DIR}"/*.txt | sort -u > "${OUTPUT_DIR}/vapt_${TARGET}_urls_all.txt"

echo "Found $(cat "${OUTPUT_DIR}/vapt_${TARGET}_urls_all.txt" | wc -l) unique URLs"
